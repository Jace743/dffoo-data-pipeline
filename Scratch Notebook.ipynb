{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c332bac-a681-46a4-9eb0-388c9e059f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import html\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7478cf9-9a77-4c91-837c-e8c2771472a3",
   "metadata": {},
   "source": [
    "# Next cells contain function definitions just to save time.\n",
    "\n",
    "I'll organize these differently once I'm done developing this part of the scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1524f75-91a8-400f-bab3-839296de2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_character_links(character_list_url):\n",
    "    \"\"\"\n",
    "\n",
    "    Generates a dictionary with character names as the keys. Values for these keys are\n",
    "    dictionaries, which contain links to the character's profile, ability, buff,\n",
    "    high armor, and high armor plus pages.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    driver.get(character_list_url)\n",
    "    \n",
    "    character_link_list = WebDriverWait(\n",
    "        driver,\n",
    "        timeout=10\n",
    "    ).until(\n",
    "        EC.presence_of_all_elements_located((By.CLASS_NAME, \"characterlink\"))\n",
    "    )\n",
    "    \n",
    "    character_dict_omnibus = {}\n",
    "    \n",
    "    for char_link in character_link_list:\n",
    "        char_name = str(char_link.get_attribute(\"href\").split('/')[-1])\n",
    "        link_to_profile = str(char_link.get_attribute(\"href\"))\n",
    "        link_to_abilities = str(f\"https://dissidiacompendium.com/characters/{char_name}/abilities?\")\n",
    "        link_to_buffs = str(f\"https://dissidiacompendium.com/characters/{char_name}/buffs?\")\n",
    "        link_to_ha = str(f\"https://dissidiacompendium.com/characters/{char_name}/gear?7A=true\")\n",
    "        link_to_ha_plus = str(f\"https://dissidiacompendium.com/characters/{char_name}/gear?7APlus=true\")\n",
    "        \n",
    "        char_dict = {\n",
    "                'profile_url': link_to_profile,\n",
    "                'abilities_url': link_to_abilities,\n",
    "                'buffs_url': link_to_buffs,\n",
    "                'high_armor_url': link_to_ha,\n",
    "                'high_armor_plus_url': link_to_ha_plus\n",
    "        }\n",
    "        \n",
    "        character_dict_omnibus[char_name] = char_dict\n",
    "\n",
    "    return character_dict_omnibus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "700d2a09-be0c-4b5f-9b70-a134907c0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ability_dict(\n",
    "    char_name,  # Character name, as a string\n",
    "    scroll_speed = 1000,  # Scrolling speed to move through the page for lazy loading\n",
    "    verbose = False  # If true, will return print statements on iterations\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    Parses a character's ability page to college abilities with HP attacks in them. The function\n",
    "    returns an ability dictionary, where the keys are the ability names in human-readable\n",
    "    format, and the values are the <div> block containing the number of BRV attacks, HP\n",
    "    attacks, buffs granted, attack attributes, etc. of the ability\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        driver.get(character_dict_omnibus[char_name]['abilities_url'])\n",
    "    except:\n",
    "        print(\"You need to generate the character_dict_omnibus first (run generate_character_links).\")\n",
    "        return\n",
    "\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        list_build_complete = False\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        while list_build_complete == False:\n",
    "            \n",
    "            driver.execute_script(f\"window.scrollBy(0, {scroll_speed});\")\n",
    "            time.sleep(1)\n",
    "            ability_list = driver.find_elements(By.XPATH, \"//div[@class='infotitle abilitydisplayfex ']\")\n",
    "            \n",
    "            # The last two abilities are calls. So, the second to last ability should be a call when we're done.\n",
    "            match = re.search('\\(C\\)', ability_list[-2].text)\n",
    "            list_build_complete = True if match else False\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"This iteration caught {len(ability_list)} abilities.\")\n",
    "            \n",
    "                print('-----------')\n",
    "            count += 1\n",
    "            if count == 15:\n",
    "                print(\"Too many iterations. Examine this function for:\")\n",
    "                print(link_to_char_ability_page)\n",
    "                break\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"This took {count} iterations.\\n\")\n",
    "        \n",
    "            for ability in ability_list:\n",
    "                print(ability.text)\n",
    "    \n",
    "        ability_info_list = driver.find_elements(By.XPATH, \"//div[@class='bluebase abilityinfobase']\")\n",
    "    \n",
    "        if verbose:\n",
    "            print(f\"Collected ability info list\")\n",
    "        \n",
    "        ability_dict = {}\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        for ability in ability_list:\n",
    "            ability_name = str(ability_list[count].text.split(' - ')[0])\n",
    "            \n",
    "            ability_dict[ability_name] = ability_info_list[count]\n",
    "            count += 1\n",
    "    \n",
    "        if verbose:\n",
    "            print('Added char name to ability dict')\n",
    "        \n",
    "        return ability_dict\n",
    "    except:\n",
    "        print(\"Unable to access abilities for a character. Maybe not on GL yet.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eba6a16-4db2-444e-a977-c8f077b61711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify_html_to_list(html_element):\n",
    "    \"\"\"\n",
    "\n",
    "    Parses a string of HTML (such as the results of .get_attribute('outerHTML') from Selenium) and \n",
    "    returns a list, where each list element is a line of the prettified HTML. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(html_element.get_attribute('outerHTML'), 'lxml')\n",
    "\n",
    "    return [line for line in soup.prettify().split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d529e9e-3c14-486a-9af3-5f5d48178037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ability_hp_attack_count(\n",
    "    char_name,  # Character name, as a string\n",
    "    scroll_speed = 1000,  # Scrolling speed to move through the page for lazy loading\n",
    "    verbose = False  # If true, will return print statements on iterations\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    Extracts the number of HP attacks dealt to an ability's main target and non-targets. The\n",
    "    function input should be a character name (char_name) in string format. Utilizes the \n",
    "    `generate_ability_dict` function.\n",
    "\n",
    "    Returns a pandas dataframe with the ability name, number of HP attacks into main targets, \n",
    "    and number of HP attacks into non-targets.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ability_dictionary = generate_ability_dict(\n",
    "        char_name = char_name, \n",
    "        scroll_speed = scroll_speed, \n",
    "        verbose = verbose\n",
    "    )\n",
    "    \n",
    "    df_row_list = []\n",
    "    \n",
    "    for ability_name, ability_div in ability_dictionary.items():\n",
    "    \n",
    "        if ability_name == 'char_name':\n",
    "            continue\n",
    "        \n",
    "        ability_html_lines = prettify_html_to_list(ability_div)\n",
    "    \n",
    "        row_dict = {}\n",
    "\n",
    "        row_dict['ability_name'] = ability_name\n",
    "        \n",
    "        main_target_hp_attacks = 0\n",
    "        non_target_hp_attacks = 0\n",
    "        hp_dmg_cap_up_perc = 0\n",
    "    \n",
    "        for index, line in enumerate(ability_html_lines):\n",
    "            \n",
    "            # Extract HP Dmg Cap within ability and/or from FE\n",
    "            \n",
    "            if re.search(\"- MAX BRV Cap\", line):\n",
    "                hp_dmg_cap_up_perc += int(ability_html_lines[index + 6].strip().replace('%', ''))\n",
    "            \n",
    "            if re.search(\"MAX BRV Cap Up by\", line):\n",
    "                hp_dmg_cap_up_perc += int(ability_html_lines[index + 2].strip().replace('%', ''))\n",
    "            \n",
    "            # \"inline HP\" is class for the HP Attack icon\n",
    "            if \"inline HP\" not in line:\n",
    "                continue\n",
    "            \n",
    "            # Info on single-target vs group attack appears on preceding line and/or 3 lines before\n",
    "            \n",
    "            single_or_group_lines = ability_html_lines[index - 1] + ability_html_lines[index - 3] + ability_html_lines[index + 2]\n",
    "            \n",
    "            AOE = True if re.search(r\"Group\", single_or_group_lines) else False\n",
    "\n",
    "            # Sometimes an inline appears after the inline(s) we care about to describe the source \n",
    "            # of the HP damage. We want to skip these instances.\n",
    "            if re.search(r\"Attack\", ability_html_lines[index - 2]):\n",
    "                continue\n",
    "            \n",
    "            # Info on HP attack count and type appears two lines later (e.g., Attack 3 times,\n",
    "            # Damage to non-targets after each HP attack, etc.), with a few exceptions.\n",
    "\n",
    "            # I hate hard coding an ability name like this, but we'll see if I can make it more\n",
    "            # programmatic later, or make a list of abilities that operate with this format.\n",
    "            \n",
    "            if ability_name == 'Crystal Generation':\n",
    "                attack_info_line = ability_html_lines[index + 6]\n",
    "            else:\n",
    "                attack_info_line = ability_html_lines[index + 2]\n",
    "\n",
    "            extra_condition_line = ability_html_lines[index + 6]\n",
    "\n",
    "            # Some abilities deal damage based on a stored value (e.g., Aerith BT effect, Astos)\n",
    "            # For these abilities, the line we want appears eleven lines later\n",
    "            if re.search(r\"Damage by\", attack_info_line) and re.search(r\"of stored value from\", extra_condition_line):\n",
    "                attack_info_line = ability_html_lines[index + 11]\n",
    "            \n",
    "            # Other abilities deal damage based on a characters stat or current value (e.g., Aerith's LD followup)\n",
    "            # For these abilities, the line we want appears six lines later\n",
    "            if re.search(r\"Damage \", attack_info_line) and re.search(r\"of \", extra_condition_line):\n",
    "                attack_info_line = ability_html_lines[index + 6]\n",
    "        \n",
    "            hp_attacks_to_add = 0\n",
    "            add_to_non_target = 0\n",
    "            copy_st_to_aoe = False\n",
    "        \n",
    "            if re.search(r\"Damage to non-targets after each HP Attack\", attack_info_line):\n",
    "                copy_st_to_aoe = True\n",
    "            elif re.search(r\"Group \\d+\", attack_info_line):\n",
    "                AOE = True\n",
    "                hp_attacks_to_add = int(re.search(r\"Group \\d+ times\", attack_info_line).group().split(' ')[1])\n",
    "            elif re.search(r\"Group\", attack_info_line):\n",
    "                AOE = True\n",
    "                hp_attacks_to_add = 1\n",
    "            elif re.search(r\"to non-targets × \\d+\", attack_info_line):\n",
    "                add_to_non_target = int(re.search(r\"× \\d+\", attack_info_line).group().split(' ')[1])\n",
    "            elif re.search(r\"to non-targets \\d+ times\", attack_info_line):\n",
    "                add_to_non_target = int(re.search(r\"\\d+ times\", attack_info_line).group().split(' ')[0])\n",
    "            elif re.search(r\"to non-targets\", attack_info_line):\n",
    "                add_to_non_target = 1\n",
    "            elif re.search(r\"\\d+ times\", attack_info_line):\n",
    "                hp_attacks_to_add = int(re.search(\"\\d+ times\", attack_info_line).group().split(' ')[0])\n",
    "            else:\n",
    "                hp_attacks_to_add = 1\n",
    "        \n",
    "            if AOE:\n",
    "                main_target_hp_attacks += hp_attacks_to_add\n",
    "                non_target_hp_attacks += hp_attacks_to_add\n",
    "            elif copy_st_to_aoe:\n",
    "                non_target_hp_attacks = main_target_hp_attacks\n",
    "            else:\n",
    "                main_target_hp_attacks += hp_attacks_to_add\n",
    "                non_target_hp_attacks += add_to_non_target\n",
    "        \n",
    "        row_dict['main_target_hp_attacks'] = main_target_hp_attacks\n",
    "        row_dict['non_target_hp_attacks'] = non_target_hp_attacks\n",
    "        row_dict['hp_dmg_cap_up_perc'] = hp_dmg_cap_up_perc\n",
    "\n",
    "        df_row_list.append(row_dict)\n",
    "\n",
    "    ability_df = pd.DataFrame(df_row_list)\n",
    "\n",
    "    ability_df['char_name'] = char_name\n",
    "    \n",
    "    filtered_df = ability_df[~ability_df['ability_name'].str.contains('(C)', regex = False)].query(\n",
    "        'main_target_hp_attacks > 0'\n",
    "    ).reset_index(drop = True)\n",
    "\n",
    "    return filtered_df[['char_name', 'ability_name', 'main_target_hp_attacks', 'non_target_hp_attacks', 'hp_dmg_cap_up_perc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e742dd94-2d24-4701-95b1-32c93f3b5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_case_ability_dfs(list_of_character_names):\n",
    "    \"\"\"\n",
    "\n",
    "    Save out characters whose HP attack counts we're confident in. We can then use these\n",
    "    test cases to see whether we've broken a previous character's df when we make changes.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for t_case in list_of_character_names:\n",
    "        ability_dict = generate_ability_dict(character_link_dict[t_case]['abilities_url'])\n",
    "    \n",
    "        df = extract_ability_hp_attack_count(ability_dict)\n",
    "\n",
    "        print(t_case.upper(), \"test case df\")\n",
    "        display(df)\n",
    "    \n",
    "        df.to_csv(\n",
    "            f\"C:\\\\Users\\\\jasre\\\\Code\\\\dffoo-data-pipeline\\\\character_ability_test_cases\\\\{t_case}_ability_df.csv\",\n",
    "            index = False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e56812e6-c055-4dd0-af1b-bd648f01da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test__recent_changes_have_not_altered_previous_ability_dfs(list_of_character_names):\n",
    "    \"\"\"\n",
    "\n",
    "    Compares a newly-generated ability df to one that was generated in the past to see if\n",
    "    recent changes have broken functionality for a previously-completed character.\n",
    "\n",
    "    Accepted characters for now: \n",
    "        ['auron', 'sherlotta', 'aerith', 'lenna', 'warrioroflight', 'astos', 'paine']\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    broken_characters_list = []\n",
    "    \n",
    "    for t_case in list_of_character_names:\n",
    "        new_ability_dict = generate_ability_dict(character_link_dict[t_case]['abilities_url'])\n",
    "\n",
    "        new_df = extract_ability_hp_attack_count(new_ability_dict)\n",
    "\n",
    "        try:\n",
    "            old_df = pd.read_csv(\n",
    "                f\"C:\\\\Users\\\\jasre\\\\Code\\\\dffoo-data-pipeline\\\\character_ability_test_cases\\\\{t_case}_ability_df.csv\"\n",
    "            )\n",
    "        except:\n",
    "            print(f\"Could not load a previous ability_df for {t_case.title()}.\")\n",
    "            print(\"Are you sure one was previously generated?\")\n",
    "\n",
    "            continue\n",
    "\n",
    "        if len(old_df.compare(new_df)) > 0:\n",
    "            broken_characters_list.append(t_case)\n",
    "\n",
    "    if len(broken_characters_list) > 0:\n",
    "        print(\"Broken ability_dfs were found.\\n Returning list of characters to review.\")\n",
    "        return broken_characters_list\n",
    "    else:\n",
    "        print(\"No broken ability_dfs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c59ac697-2e71-4efe-bafb-ce700e672e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_hp_caps_from_bt(\n",
    "    char_name,  # Character's name as a string\n",
    "    verbose = False  # If true, will return print statements\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Takes a character's name as input and returns a dictionary with three key-value pairs:\n",
    "\n",
    "    1) Character's name\n",
    "    2) Personal HP Dmg Cap up from BT effect\n",
    "    3) Party-side HP Dmg Cap up from BT effect\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    actions = ActionChains(driver)\n",
    "    \n",
    "    driver.get(character_link_dict[char_name]['buffs_url'])\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    bt_personal_hp_dmg_cap_up = 0\n",
    "    bt_party_hp_dmg_cap_up = 0\n",
    "    \n",
    "    try:\n",
    "        # Find the BT button for the character's buff page\n",
    "        bt_button_element = driver.find_element(By.XPATH, \"//li[@class='filterinactive buffbutton wpbtbutton']\")\n",
    "    except:\n",
    "        print(f\"Unable to find a BT for {char_name.title()}. Do they have one in this timeline (GL/JP)?\")\n",
    "        return\n",
    "        \n",
    "    # Click on it to make sure that the buff appears\n",
    "    actions.click(bt_button_element)\n",
    "    \n",
    "    # Scroll down to make sure the BT buff loads fully\n",
    "    driver.execute_script(f\"window.scrollBy(0, 600);\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "    # Set leveled BT to max before extracting auras\n",
    "    try:\n",
    "        if driver.find_element(By.XPATH, \"//div[@class='sliderbase infonameholder nobuffpadding']\"):\n",
    "            \n",
    "            pretty_div_block_list = prettify_html_to_list(\n",
    "                driver.find_element(\n",
    "                    By.XPATH, \"//div[@class='sliderbase infonameholder nobuffpadding']\"\n",
    "                )\n",
    "            )\n",
    "    \n",
    "            # Note to self for later -- not relevant for actual code\n",
    "            if char_name in ['lannreynn', 'paine']:\n",
    "                print(\n",
    "                    f\"NOTE: {char_name.upper()} has something about them\"\n",
    "                )\n",
    "                print(\n",
    "                    \"that you need to consider before adding new features!\"\n",
    "                )\n",
    "                \n",
    "            try:\n",
    "                # find slider class\n",
    "                for line in pretty_div_block_list:\n",
    "                    if re.search(r'css-(\\w+)-Slider', line):\n",
    "                        slider_class = re.search(r'css-\\w+-Slider', line).group()\n",
    "    \n",
    "                # Find width element class\n",
    "                for line in pretty_div_block_list:\n",
    "                    if re.search(r'(css-\\w+)(\" style)', line):\n",
    "                        width_element_class = re.search(r'(css-\\w+)(\" style)', line).group(1)\n",
    "                \n",
    "                slider = driver.find_element(By.XPATH, f\"//div[@class='{slider_class}']\")\n",
    "                width_element = driver.find_element(By.XPATH, f\"//div[@class='{width_element_class}']\")\n",
    "                \n",
    "            except:\n",
    "                print(\"There's a new BT Effect slider for you to figure out.\")\n",
    "                return\n",
    "    \n",
    "        initial_x_offset = offset = 80\n",
    "    \n",
    "        while width_element.get_attribute('style') != 'width: 100%;':\n",
    "            offset += 10\n",
    "            actions.drag_and_drop_by_offset(slider, offset, 0).release().perform()\n",
    "            if verbose:\n",
    "                print(f\"Offset of {offset} performed.\")\n",
    "    \n",
    "        if verbose:\n",
    "            print(\"Reached max stacks!\")\n",
    "    except:\n",
    "        if verbose:\n",
    "            print(f\"No stack slider found. Assuming {char_name} has a BT without stacks.\")\n",
    "        pass\n",
    "    \n",
    "    bt_buff_description_div = driver.find_element(\n",
    "        By.XPATH, \"//div[@class='Buffbase infobase nobuffpadding']\"\n",
    "    )\n",
    "    \n",
    "    bt_buff_html_list = prettify_html_to_list(bt_buff_description_div)\n",
    "    \n",
    "    for index, line in enumerate(bt_buff_html_list):\n",
    "        \n",
    "        if re.search(r\"- MAX BRV Cap\", line):  # Personal HP Dmg Cap Up has this string\n",
    "            bt_personal_hp_dmg_cap_up += int(re.search(r\"\\d+\", bt_buff_html_list[index + 6]).group())\n",
    "        if re.search(r\"- Party MAX BRV Cap\", line):  # Party HP Dmg Cap up has this string\n",
    "            bt_party_hp_dmg_cap_up += int(re.search(r\"\\d+\", bt_buff_html_list[index + 6]).group())\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Personal HP Dmg Cap Up: {bt_personal_hp_dmg_cap_up}%\")\n",
    "        print(f\"Party HP Dmg Cap Up: {bt_party_hp_dmg_cap_up}%\")\n",
    "\n",
    "    bt_effect_dict = {}\n",
    "    bt_effect_dict['char_name'] = char_name\n",
    "    bt_effect_dict['bt_personal_hp_dmg_cap_up'] = bt_personal_hp_dmg_cap_up\n",
    "    bt_effect_dict['bt_party_hp_dmg_cap_up'] = bt_party_hp_dmg_cap_up\n",
    "\n",
    "    return bt_effect_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14682b0-b6fb-47e6-bc82-c7a1608c9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_ha_hp_dmg_cap_up(char_name, verbose=False):\n",
    "    \"\"\"\n",
    "\n",
    "    Retrieves HP Dmg Cap up values from a character's high armor pages, both personal and \n",
    "    party-wide, and returns a dictionary with three keys: 1) character name, 2) personal \n",
    "    cap up, and 3) party-wide cap up.\n",
    "\n",
    "    \"\"\"\n",
    "    driver.get(character_link_dict[char_name]['high_armor_url'])\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    high_armor_html = prettify_html_to_list(\n",
    "        driver.find_element(By.XPATH, \"//div[@class='infonameholderenemybuff default_passive Buffbase']\")\n",
    "    )\n",
    "    \n",
    "    personal_ha_hp_dmg_cap_up = 0\n",
    "    party_ha_hp_dmg_cap_up = 0\n",
    "    \n",
    "    # Extract base high armor values\n",
    "    for index, line in enumerate(high_armor_html):\n",
    "        if re.search(r\"- MAX BRV Cap\", line):\n",
    "            personal_ha_hp_dmg_cap_up += int(re.search(\"\\d+\", high_armor_html[index + 6]).group())\n",
    "        if re.search(r\"- Party MAX BRV Cap\", line):\n",
    "            party_ha_hp_dmg_cap_up += int(re.search(\"\\d+\", high_armor_html[index + 6]).group())\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Personal Cap Up: {personal_ha_hp_dmg_cap_up}\")\n",
    "        print(f\"Party Cap Up: {party_ha_hp_dmg_cap_up}\")\n",
    "    \n",
    "    driver.get(character_link_dict[char_name]['high_armor_plus_url'])\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    driver.execute_script(\"window.scrollBy(0, 300);\")\n",
    "    \n",
    "    high_armor_plus_div_list = driver.find_elements(\n",
    "        By.XPATH, \"//div[@class='infonameholderenemybuff default_passive Buffbase']\"\n",
    "    )\n",
    "    \n",
    "    # Make sure we've captured all the HA+ blocks before extracting data\n",
    "    while len(high_armor_plus_div_list) < 5:\n",
    "        driver.execute_script(\"window.scrollBy(0, 300);\")\n",
    "        high_armor_plus_div_list = driver.find_elements(\n",
    "            By.XPATH, \"//div[@class='infonameholderenemybuff default_passive Buffbase']\"\n",
    "        )\n",
    "    \n",
    "    for div_block in high_armor_plus_div_list:\n",
    "        \n",
    "        ha_plus_html = prettify_html_to_list(div_block)\n",
    "        \n",
    "        for index, line in enumerate(ha_plus_html):\n",
    "            if re.search(r\"- MAX BRV Cap\", line):\n",
    "                personal_ha_hp_dmg_cap_up += int(re.search(\n",
    "                    \"\\d+\", ha_plus_html[index + 6]\n",
    "                ).group())\n",
    "    \n",
    "            if re.search(r\"- Party MAX BRV Cap\", line):\n",
    "                party_ha_hp_dmg_cap_up += int(re.search(\n",
    "                    \"\\d+\", ha_plus_html[index + 6]\n",
    "                ).group())\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Personal Cap Up: {personal_ha_hp_dmg_cap_up}\")\n",
    "        print(f\"Party Cap Up: {party_ha_hp_dmg_cap_up}\")\n",
    "\n",
    "    ha_hp_dmg_cap_up_dict = {}\n",
    "    ha_hp_dmg_cap_up_dict['char_name'] = char_name\n",
    "    ha_hp_dmg_cap_up_dict['personal_hp_dmg_cap_up'] = personal_ha_hp_dmg_cap_up\n",
    "    ha_hp_dmg_cap_up_dict['party_ha_hp_dmg_cap_up'] = party_ha_hp_dmg_cap_up\n",
    "\n",
    "    return ha_hp_dmg_cap_up_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a40a9e-b7cf-45fa-b59d-c58060d1efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_inline_ability_attributes(\n",
    "    char_name, \n",
    "    scroll_speed = 1000, \n",
    "    verbose = False\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Takes a character name and extracts all of the inline attributes of their abilities. Returns\n",
    "    this information in a dictionary with ability name as keys and a list of inline attributes as\n",
    "    values.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    driver.get(character_link_dict[char_name]['abilities_url'])\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    list_build_complete = False\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    while list_build_complete == False:\n",
    "        \n",
    "        driver.execute_script(f\"window.scrollBy(0, 1000);\")\n",
    "        time.sleep(1)\n",
    "        ability_list = driver.find_elements(By.XPATH, \"//div[@class='infotitle abilitydisplayfex ']\")\n",
    "        \n",
    "        # The last two abilities are calls. So, the second to last ability should be a call when we're done.\n",
    "        match = re.search('\\(C\\)', ability_list[-2].text)\n",
    "        list_build_complete = True if match else False\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"This iteration caught {len(ability_list)} abilities.\")\n",
    "        \n",
    "            print('-----------')\n",
    "        count += 1\n",
    "        if count == 15:\n",
    "            print(\"Too many iterations. Examine this function for:\")\n",
    "            print(link_to_char_ability_page)\n",
    "            break\n",
    "    \n",
    "    ability_attribute_dict = {}\n",
    "    \n",
    "    for index, ability_div in enumerate(ability_list):\n",
    "        inline_attribute_list  = []\n",
    "        \n",
    "        ability_name = str(ability_list[index].text.split(' - ')[0])\n",
    "        \n",
    "        ability_div_html = prettify_html_to_list(ability_div)\n",
    "    \n",
    "        for line in ability_div_html:\n",
    "            if re.search(r\"inline \", line):\n",
    "                inline_attribute = re.search(r\"(inline )(\\w+)\", line).group(2)\n",
    "                inline_attribute_list.append(inline_attribute)\n",
    "    \n",
    "        ability_attribute_dict[ability_name] = inline_attribute_list\n",
    "\n",
    "    return ability_attribute_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8160d4b-195f-4c84-a6a9-2337da3abaae",
   "metadata": {},
   "source": [
    "# Goals for Scraper\n",
    "\n",
    "- Pull character list\n",
    "- Extract data from character sheet\n",
    "- Organize data into sensible datasets for later use\n",
    "\n",
    "## Pull Character List\n",
    "Done! :)\n",
    "\n",
    "## Extract Data from Character Sheet\n",
    "1. Navigate to character's sheet\n",
    "2. Pull data on all their attacks\n",
    "3. Pull data on their HA\n",
    "4. Pull data on their BT effect\n",
    "6. Pull data on their FE\n",
    "\n",
    "## Organize data into sensible datasets for later use\n",
    "1. Character-Level\n",
    "    1. BT Effect HP Cap Up\n",
    "    2. HA HP Cap Up\n",
    "2. Attacks (for each: # of split AoE attacks, full AoE attacks, ST attacks, and HP Cap Additions -- this will require info from FE)\n",
    "   1. BRV(+) Attacks\n",
    "   2. HP(+) Attacks\n",
    "   3. S1\n",
    "   4. S2\n",
    "   5. EX\n",
    "   6. LD\n",
    "   7. BT\n",
    "   8. FR\n",
    "\n",
    "# Other Miscellaneous Notes\n",
    "- For characters with a rework, parse their GL profile first. It doesn't look like you can easily toggle back to GL from JP.\n",
    "- The best thing to do is probably to parse all of GL first, and then go back and parse all of JP.\n",
    "- Write something that will check whether each character has a JP rework, and if it does, add them to a list of characters to parse through for reworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9bf56ce9-001d-45d2-b357-ab97b837bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_list_url = 'https://dissidiacompendium.com/characters/?'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "character_link_dict = generate_character_links(character_list_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bade29c1-b678-460c-910e-f8276cf7711b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jecht Beam is a follow-up!\n"
     ]
    }
   ],
   "source": [
    "ability_attribute_dict = extract_inline_ability_attributes('braska')\n",
    "\n",
    "for ability_name, attribute_list in ability_attribute_dict.items():\n",
    "    if 'FollowUp' in attribute_list:\n",
    "        print(f\"{ability_name} is a follow-up!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d457b8-c814-42d3-bdd4-af78c5d7d52b",
   "metadata": {},
   "source": [
    "# Notes on language of follow-up attacks in Dissidia Compendium\n",
    "\n",
    "Honestly, there doesn't seem to be any consistency across follow-ups, and there doesn't seem to be language that consistently indicates whether a follow-up should be included in launch or not. Here are a few examples:\n",
    "\n",
    "- 'braska': \"At start of next turn\",  # Not included in launch\n",
    "- 'machina': \"after inflicter attacks a target afflicted with...\",  # Included in launch\n",
    "- 'lenna': \"follow up when attacking an enemy while...\",  # Included in launch\n",
    "- 'rosa': \"after own turn...\",  # Not included in launch\n",
    "- 'reks': \"before turn while...\", # Not included in launch\n",
    "- 'cissnei': \"... after Party attack\",  # Not included in launch\n",
    "- 'ardyn': \"After attacks while buffed with...\",  # Included in launch\n",
    "- 'noctis': [\"After attacking an enemy afflicted with...\",  # Included in launch\n",
    "           \"While... and after any party member acts against a target\"],  # Not included in launch\n",
    "- 'zack': \"When attacking enemy targeting self\"  # Included in launch\n",
    "\n",
    "So... I think this means that I may just have to hard-code all of these. I should design what information I want to go into the df that I'll extract for follow ups. Maybe:\n",
    "\n",
    "1. Before (e.g., Reks), during (e.g., Balthier, Tifa, Zack), or after turn (e.g., Rosa, Jihl)\n",
    "2. Included in launch or not\n",
    "3. Associated abilities (I can say \"all\" for follow ups that occur regardless of what ability is used, and I can provide a list or specific ability name as applicable, such as for Zack's Chain Slash follow up)\n",
    "4. The HP attack and MBRV Cap information from my previous work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682c9c7-dcc3-4579-864e-83cbd3ebe762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
